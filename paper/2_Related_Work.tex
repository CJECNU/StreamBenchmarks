\section{Related work}
\label{rel}
The main concepts and methodologies used in benchmarking SDPSs are inherited from benchmarks of  batch processing engines.
Now with emerging next generation stream data processing engines, batch processing is seen as a special case of stream processing where the data size is bounded. Huang et.al. propose HiBench, the first benchmark suite for evaluation and characterization of Hadoop \cite{white2012hadoop}. Authors conduct wide range of experiments from micro-benchmarks to machine learning algorithms \cite{huang2011hibench}. Covering end-to-end big data benchmark with all major characteristics such as three Vs in the lifecycle of big data systems is the main intuition behind BigBench \cite{ghazal2013bigbench}. Wang et.al. introduce BigDataBench, a big data benchmark suite for Internet Services, characterising the 19 big data benchmarks covering broad application scenarios and diverse and representative data sets \cite{wang2014bigdatabench}.

 Benchmarks on SDPS are  Researchers from Yahoo Inc. have done benchmarks on streaming systems to measure latency and throughput \cite{chintapalli2016benchmarking}. They used Apache Kafka \cite{kafka2014high} and Redis \cite{carlson2013redis} for data fetching and storage. Later on, on the other hand, Data Artisans, showed those systems actually being a bottleneck for SUT's performance \cite{dataartisans}.  The extensive analysis of the differences between Apache Spark and Apache Flink in terms of batch processing is done by correlating the operators execution plan with the resource utilization and the parameter configuration \cite{marcu2016spark}. In another benchmark, authors compare the performances of Apache Spark and Apache Flink to  provide clear, easy and reproducible configurations that can be validated by community in clouds \cite{perera2016reproducible}. Authors conducted  benchmarks to assess the fault tolerance and throughput efficiency for open source stream data processing engines \cite{lopez2016performance}. In another benchmark, authors motivate IoT as being main application area for SDPS and perform common tasks in particular are with different stream data processing engines and evaluate performance \cite{shukla2016benchmarking}. One of the pioneers in SDPS benchmarks, developed framework StreamBench analysing the current standards in streaming benchmarks and proposing a solution to measure throughput, latency considering the fault tolerance of SUT \cite{lu2014stream}. Authors put a mediator system between data generator module and SUT and define the latency as the average time span from the arrival of a record till the end of processing of the record. LinearRoad benchmarking framework was presented by Arasu et al. to measure performance of standalone stream data management systems such as Aurora \cite{abadi2003aurora} by simulating a scenario of toll system for motor vehicle expressways. Several stream processing systems implement their own benchmarks to assess the performance \cite{neumeyer2010s4,qian2013timestream,zaharia2012discretized}. SparkBench is a benchmarking framework to evaluate machine learning, graph computation, SQL query and streaming application on top of Apache Spark \cite{li2015sparkbench}.
